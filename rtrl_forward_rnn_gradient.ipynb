{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc7a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ipycanvas\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6231e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3456, -0.3735]) tensor([ 0.1448, -0.2196]) tensor([ 0.3456, -0.3735], grad_fn=<MulBackward0>) tensor([ 0.1448, -0.2196], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def compute(x, h1, gt1_w1, gt1_w2, w1, w2):\n",
    "    # Single recursive node\n",
    "    y = w1 * x + w2 * h1\n",
    "    # dh1/dh2 * dh2/dw + dh1/dw\n",
    "    gt_w1 = w2 * gt1_w1 + x\n",
    "    gt_w2 = w2 * gt1_w2 + h1\n",
    "    return y, gt_w1, gt_w2\n",
    "\n",
    "\n",
    "w1 = torch.rand(2, requires_grad=True)\n",
    "w2 = torch.rand(2, requires_grad=True)\n",
    "h0 = 0\n",
    "x1 = torch.rand(2, requires_grad=True)\n",
    "h1, dh_w1, dh_w2 = compute(x1, h0, 0, 0, w1, w2)\n",
    "#assert h1 == 1\n",
    "\n",
    "x2 = torch.rand(2, requires_grad=True)\n",
    "h2, dh_w1, dh_w2 = compute(x2, h1, dh_w1, dh_w2, w1, w2)\n",
    "#assert h2 == (1.5 + 0.5)\n",
    "\n",
    "x3 = torch.rand(2, requires_grad=True)\n",
    "h3, dh_w1, dh_w2 = compute(x3, h2, dh_w1, dh_w2, w1, w2)\n",
    "\n",
    "y = torch.rand(2)\n",
    "loss = torch.nn.MSELoss()(h3, y)\n",
    "loss.backward()\n",
    "\n",
    "error_grad = 2 * (h3 - y) / 2\n",
    "# YAY! gt1_w1 is correct! With gt_w1 = w2 * gt1_w1 + x\n",
    "# YAY! gt1_w2 is correct! With gt_w2 = w2 * gt1_w2 + h1\n",
    "print(w1.grad, w2.grad, dh_w1*error_grad, dh_w2*error_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bd3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "c = ipycanvas.Canvas(width=800, height=200)\n",
    "\n",
    "def draw_node(c, x, y):\n",
    "    c.stroke_style = \"red\"\n",
    "    c.stroke_circle(x, y, 40)\n",
    "\n",
    "def draw_recurrent_node(c, x=60, y=100):\n",
    "\n",
    "    draw_node(c, x, y)\n",
    "\n",
    "    c.begin_path()\n",
    "    y_arc = y - 40\n",
    "    x0 = x+15\n",
    "    x1 = x-15\n",
    "    c.move_to(x0, y_arc)\n",
    "    c.quadratic_curve_to(x0 + 5, y_arc-25, x0 + (x1 - x0)//2, y_arc - 25)\n",
    "    c.quadratic_curve_to(x1 - 5, y_arc-25, x1, y_arc)\n",
    "    c.stroke()\n",
    "    c.begin_path()\n",
    "    arrow_width = 5\n",
    "    c.line_to(x1-arrow_width, y_arc)\n",
    "    c.line_to(x1, y_arc+arrow_width)\n",
    "    c.line_to(x1+arrow_width, y_arc)\n",
    "    c.fill()\n",
    "    \n",
    "def draw_arrow(c, x0, y0, x1, y1, arrow_width=5, direction=\"right\"):\n",
    "    c.begin_path()\n",
    "    c.move_to(x0, y0)\n",
    "    c.line_to(x1, y1)\n",
    "    c.stroke()\n",
    "    c.begin_path()\n",
    "    if direction == \"right\":\n",
    "        c.line_to(x1-arrow_width, y1-arrow_width)\n",
    "        c.line_to(x1-arrow_width, y1+arrow_width)\n",
    "        c.line_to(x1, y1)\n",
    "    elif direction == \"left\":\n",
    "        c.line_to(x1+arrow_width, y1-arrow_width)\n",
    "        c.line_to(x1+arrow_width, y1+arrow_width)\n",
    "        c.line_to(x1, y1)\n",
    "    elif direction == \"down\":\n",
    "        c.line_to(x1+arrow_width, y1-arrow_width)\n",
    "        c.line_to(x1-arrow_width, y1-arrow_width)\n",
    "        c.line_to(x1, y1)\n",
    "    else:\n",
    "        c.line_to(x1+arrow_width, y1+arrow_width)\n",
    "        c.line_to(x1-arrow_width, y1+arrow_width)\n",
    "        c.line_to(x1, y1)\n",
    "    c.fill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e73569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ffbda5e144b469b466de6ba44db4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=300, width=800)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ipycanvas.Canvas(width=800, height=300)\n",
    "\n",
    "\n",
    "\n",
    "def draw_node_layer(c, x_left, x_right, y_top, y_bottom, radius, n1, n2):\n",
    "    draw_recurrent_node(c, x=x_right, y=y_top)\n",
    "    draw_recurrent_node(c, x=x_right, y=y_bottom)\n",
    "\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_top,    x1=x_right-radius, y1=y_top,    direction=\"right\")\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_bottom, x1=x_right-radius, y1=y_bottom, direction=\"right\")\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_top,    x1=x_right-radius, y1=y_bottom, direction=\"right\")\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_bottom, x1=x_right-radius, y1=y_top,    direction=\"right\")\n",
    "\n",
    "    draw_arrow(c, x0=x_right+5, y0=y_bottom-radius, x1=x_right+5, y1=y_top+radius,    direction=\"up\")\n",
    "    draw_arrow(c, x0=x_right-5, y0=y_top+radius,    x1=x_right-5, y1=y_bottom-radius, direction=\"down\")\n",
    "    \n",
    "    c.fill_text(n1, x_right-5, y_top+10)\n",
    "    c.fill_text(n2, x_right-5, y_bottom+10)\n",
    "\n",
    "draw_node(c, x=60, y=100)\n",
    "draw_node(c, x=60, y=220)\n",
    "c.font = '24px serif'\n",
    "c.fill_text(\"2\", 55, 230)\n",
    "c.fill_text(\"3\", 55, 110)\n",
    "\n",
    "draw_node_layer(c, x_left=60, x_right=200, y_top=100, y_bottom=220, radius=40, n1=\"0\", n2=\"1\")\n",
    "\n",
    "\n",
    "c.font = '12px serif'\n",
    "c.fill_text(\"num_hidden=2 num_inputs=2\", 40, 10)\n",
    "\n",
    "display(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380b196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(330.9234, grad_fn=<MseLossBackward0>) tensor([[10.9442],\n",
      "        [12.0475],\n",
      "        [13.2783]], grad_fn=<DivBackward0>)\n",
      "===== Calculated =====\n",
      "tensor([[538.6920, 421.2439, 533.8552, 246.4551, 298.0990,  83.9137,  89.0699],\n",
      "        [231.0111, 210.3058, 250.2911,  65.7034,  78.2123,  32.0094,  30.8143],\n",
      "        [482.5910, 389.2635, 486.9231, 206.2603, 248.4964,  73.6297,  77.3962]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "===== Actual =====\n",
      "tensor([[538.6920, 421.2439, 533.8553, 246.4551, 298.0990,  83.9137,  89.0699],\n",
      "        [231.0111, 210.3058, 250.2911,  65.7034,  78.2123,  32.0094,  30.8143],\n",
      "        [482.5910, 389.2635, 486.9231, 206.2603, 248.4964,  73.6297,  77.3962]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/.local/lib/python3.8/site-packages/torch/testing/_deprecated.py:35: FutureWarning: torch.testing.assert_allclose() is deprecated since 1.12 and will be removed in 1.14. Use torch.testing.assert_close() instead. For detailed upgrade instructions see https://github.com/pytorch/pytorch/issues/61844.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def calc_next_G_fc_loop(G, W, inputs, hiddens):\n",
    "    G_new = torch.zeros_like(G, requires_grad=False)\n",
    "    for k in range(G.shape[0]):\n",
    "        for i in range(G.shape[1]):\n",
    "            for j in range(G.shape[2]):\n",
    "                # p should just belong to the hiddens 0,1\n",
    "                for p in range(G.shape[0]):\n",
    "                    G_new[k,i,j] += W[k,p] * G[p,i,j]\n",
    "                # if the destination equals a node to backprop from\n",
    "                if i == k:\n",
    "                    # hiddens = 0,1\n",
    "                    if j >= hiddens.shape[0]:\n",
    "                        G_new[k,i,j] += inputs[j-hiddens.shape[0], 0]\n",
    "                    else:\n",
    "                        G_new[k,i,j] += hiddens[j,0]\n",
    "    \n",
    "    return G_new\n",
    "\n",
    "def calc_next_G_fc(G, W, inputs, hiddens):\n",
    "    G_new = torch.zeros_like(G, requires_grad=False)\n",
    "    for k in range(G.shape[0]):\n",
    "        for i in range(G.shape[1]):\n",
    "            G_new[k,i:i+1,:] += torch.mm(W[k:k+1,0:G.shape[0]], G[:,i,:])\n",
    "        \n",
    "        i = k\n",
    "        for j in range(G.shape[2]):\n",
    "            if j >= hiddens.shape[0]:\n",
    "                G_new[k,i,j] += inputs[j-hiddens.shape[0], 0]\n",
    "            else:\n",
    "                G_new[k,i,j] += hiddens[j,0]\n",
    "\n",
    "    return G_new\n",
    "\n",
    "def forward_grad_2hidden_calc_activation(hiddens, G):\n",
    "    new_hiddens = torch.sigmoid(hiddens)\n",
    "    sigmoid_deriv = torch.sigmoid(hiddens) * (1 - torch.sigmoid(hiddens))\n",
    "    for k in range(G.shape[0]):\n",
    "        G[k,:,:] *= sigmoid_deriv[k]\n",
    "    return new_hiddens, G\n",
    "\n",
    "def forward_grad_2hidden_calc_fc(G, W, inputs, hiddens):\n",
    "    # Forward prop\n",
    "    z = torch.cat((hiddens, inputs))\n",
    "    new_hiddens = torch.mm(W[:hiddens.shape[0]], z)\n",
    "    # Calculate gradients\n",
    "    G = calc_next_G_fc(G, W, inputs, hiddens)\n",
    "    # Nonlinear activation\n",
    "    #new_hiddens, G = forward_grad_2hidden_calc_activation(new_hiddens, G)\n",
    "    \n",
    "    return (new_hiddens, G)\n",
    "    \n",
    "\n",
    "def forward_grad_2hidden_fc():\n",
    "    num_hidden = 3\n",
    "    num_input = 4\n",
    "    num_nodes = num_hidden + num_input\n",
    "    # Gij^k\n",
    "    G = torch.zeros((num_hidden, num_hidden, num_nodes), requires_grad=False)\n",
    "    W = torch.rand((num_hidden, num_nodes), requires_grad=True)\n",
    "    num_itr = 5\n",
    "    hidden = torch.zeros((num_hidden,1), requires_grad=False)\n",
    "    \n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        inputs = torch.rand((num_input,1))        \n",
    "        hidden, G = forward_grad_2hidden_calc_fc(G, W, inputs, hidden)\n",
    "        \n",
    "    y = torch.rand((num_hidden,1))\n",
    "    error = torch.nn.MSELoss()(hidden,y)\n",
    "    error_grad = 2 * (hidden - y) / num_hidden\n",
    "    print(error, error_grad)\n",
    "    error.backward()\n",
    "    G_grad = G\n",
    "    for i in range(error_grad.shape[0]):\n",
    "        G_grad[i,:,:] *= error_grad[i]\n",
    "    print(\"===== Calculated =====\")\n",
    "    print(G_grad.sum(dim=0))\n",
    "    print(\"===== Actual =====\")\n",
    "    print(W.grad)\n",
    "    torch.testing.assert_allclose(G_grad.sum(dim=0), W.grad)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "forward_grad_2hidden_fc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c7a725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bac20db2bbf4798b659232c032aa66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=300, width=800)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ipycanvas.Canvas(width=800, height=300)\n",
    "\n",
    "\n",
    "\n",
    "def draw_node_layer(c, x_left, x_right, y_top, y_bottom, radius, n1, n2):\n",
    "    draw_recurrent_node(c, x=x_right, y=y_top)\n",
    "    draw_recurrent_node(c, x=x_right, y=y_bottom)\n",
    "\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_top,    x1=x_right-radius, y1=y_top,    direction=\"right\")\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_bottom, x1=x_right-radius, y1=y_bottom, direction=\"right\")\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_top,    x1=x_right-radius, y1=y_bottom, direction=\"right\")\n",
    "    draw_arrow(c, x0=x_left+radius, y0=y_bottom, x1=x_right-radius, y1=y_top,    direction=\"right\")\n",
    "\n",
    "    draw_arrow(c, x0=x_right+5, y0=y_bottom-radius, x1=x_right+5, y1=y_top+radius,    direction=\"up\")\n",
    "    draw_arrow(c, x0=x_right-5, y0=y_top+radius,    x1=x_right-5, y1=y_bottom-radius, direction=\"down\")\n",
    "    \n",
    "    c.fill_text(n1, x_right-5, y_top+10)\n",
    "    c.fill_text(n2, x_right-5, y_bottom+10)\n",
    "\n",
    "draw_node(c, x=60, y=100)\n",
    "draw_node(c, x=60, y=220)\n",
    "c.font = '24px serif'\n",
    "c.fill_text(\"4\", 55, 230)\n",
    "c.fill_text(\"5\", 55, 110)\n",
    "\n",
    "draw_node_layer(c, x_left=60, x_right=200, y_top=100, y_bottom=220, radius=40, n1=\"2\", n2=\"3\")\n",
    "draw_node_layer(c, x_left=200, x_right=340, y_top=100, y_bottom=220, radius=40, n1=\"0\", n2=\"1\")\n",
    "\n",
    "\n",
    "c.font = '12px serif'\n",
    "c.fill_text(\"num_hidden=2 num_inputs=2\", 40, 10)\n",
    "    \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d3fa41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47.9713, grad_fn=<MseLossBackward0>) tensor([[5.0851],\n",
      "        [4.1420],\n",
      "        [1.3573],\n",
      "        [1.7647]], grad_fn=<DivBackward0>)\n",
      "===== Calculated =====\n",
      "tensor([[43.2505, 41.6537, 38.2249, 45.3476, 27.4623, 24.5477],\n",
      "        [33.5932, 32.2978, 29.0316, 34.4059, 20.3953, 18.3798],\n",
      "        [25.8956, 26.1423, 33.2734, 40.3334, 36.4044, 34.5322],\n",
      "        [34.2687, 35.3809, 50.4421, 61.5805, 64.4329, 64.5077]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "===== Actual =====\n",
      "tensor([[43.2505, 41.6537, 38.2249, 45.3476, 27.4623, 24.5477],\n",
      "        [33.5932, 32.2978, 29.0316, 34.4059, 20.3953, 18.3798],\n",
      "        [25.8956, 26.1423, 33.2734, 40.3334, 36.4044, 34.5322],\n",
      "        [34.2687, 35.3809, 50.4421, 61.5805, 64.4329, 64.5078]])\n"
     ]
    }
   ],
   "source": [
    "def forward_grad_4hidden_fc():\n",
    "    num_hidden = 4\n",
    "    num_input = 2\n",
    "    num_nodes = num_hidden + num_input\n",
    "    # Gij^k\n",
    "    G = torch.zeros((num_hidden, num_hidden, num_nodes), requires_grad=False)\n",
    "    W = torch.rand((num_hidden, num_nodes), requires_grad=True).detach()\n",
    "    # 16 weights vs 4*6=24 weights\n",
    "    # No connections to 0,1 from 4,5\n",
    "    W[0:2, 4:6] = 0\n",
    "    # No connections to 2,3 from 0,1\n",
    "    W[2:4, 0:2] = 0\n",
    "    W.requires_grad = True\n",
    "    # G_new[k,i,j] += W[k,p] * G[p,i,j]\n",
    "    # G[0] is still influenced by G[2]\n",
    "    # At each time step, every node is influenced by every weight by a unique value\n",
    "    num_itr = 5\n",
    "    hidden = torch.zeros((num_hidden,1), requires_grad=False)\n",
    "    \n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        inputs = torch.rand((num_input,1))        \n",
    "        hidden, G = forward_grad_2hidden_calc_fc(G, W, inputs, hidden)\n",
    "        \n",
    "    y = torch.rand((num_hidden,1))\n",
    "    error = torch.nn.MSELoss()(hidden,y)\n",
    "    error_grad = 2 * (hidden - y) / num_hidden\n",
    "    print(error, error_grad)\n",
    "    error.backward()\n",
    "    G_grad = G\n",
    "    for i in range(error_grad.shape[0]):\n",
    "        G_grad[i,:,:] *= error_grad[i]\n",
    "    print(\"===== Calculated =====\")\n",
    "    print(G_grad.sum(dim=0))\n",
    "    print(\"===== Actual =====\")\n",
    "    print(W.grad)\n",
    "    torch.testing.assert_allclose(G_grad.sum(dim=0), W.grad)\n",
    "    \n",
    "forward_grad_4hidden_fc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0085b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(2,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd26dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4662429",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (301224314.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [7]\u001b[0;36m\u001b[0m\n\u001b[0;31m    update = self.W[0,k+self.num_raw_inputs] * g_in[k]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, num_raw_inputs, num_hidden_inputs, num_nodes, is_output_node=True):\n",
    "        self.num_raw_inputs = num_raw_inputs\n",
    "        num_inputs = num_raw_inputs + num_hidden_inputs + 1\n",
    "        self.W = torch.rand((1, num_inputs), requires_grad=True, device=device)\n",
    "        self.hidden = torch.zeros((1,1), requires_grad=False, device=device)\n",
    "        \n",
    "        self.is_output_node = is_output_node\n",
    "        if self.is_output_node:\n",
    "            self.G = torch.zeros((num_inputs), requires_grad=False, device=device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        old_hidden = self.hidden\n",
    "        \n",
    "        z = torch.cat((x, old_hidden))\n",
    "        self.z = z\n",
    "        self.pending_hidden = torch.mm(self.W, z)\n",
    "        \n",
    "    def calculate_update(self, g_in, Ws):\n",
    "        # Need the G's of any node that leads to me including myself\n",
    "        self.pending_G = self.G.clone().detach()\n",
    "        with torch.no_grad():\n",
    "            self.pending_G[-1] += self.W[0,-1] * self.G[-1]\n",
    "            \n",
    "            # My result is because of any weights in the path to me\n",
    "            # Self k == p\n",
    "            for i in range(self.G.shape[0]):\n",
    "                update = self.W[0,k+self.num_raw_inputs] * g_in[k]\n",
    "                self.pending_G[k+self.num_raw_inputs] += update\n",
    "            # Others\n",
    "            for j in range(g_in[k].shape[0]):\n",
    "                # My G is increased by any path from a hidden to me\n",
    "                update = Ws[k][j] * g_in[k][j]\n",
    "                torch.testing.assert_allclose(update.shape, torch.Size([]))\n",
    "                self.pending_G[j] += update\n",
    "\n",
    "            for j in range(self.z.shape[0]):\n",
    "                self.pending_G[j] += self.z[j,0]\n",
    "            \n",
    "    def commit_update(self):\n",
    "        self.G = self.pending_G\n",
    "        print(\"New G:\", self.G[-2])\n",
    "        self.hidden = self.pending_hidden\n",
    "    \n",
    "nodes = [Node(2, 1, 1) for _ in range(2)]\n",
    "num_itrs = 2\n",
    "for _ in range(num_itrs):\n",
    "    x_in = torch.rand((2,1))\n",
    "    x_in_n0 = torch.cat((x_in, nodes[1].hidden))\n",
    "    nodes[0].forward(x_in_n0)\n",
    "    x_in_n1 = torch.cat((x_in, nodes[0].hidden))\n",
    "    nodes[1].forward(x_in_n1)\n",
    "    \n",
    "    nodes[0].calculate_update(g_in=[nodes[1].G)\n",
    "    nodes[1].calculate_update(g_in=[nodes[0].G)\n",
    "    \n",
    "    nodes[0].commit_update()\n",
    "    nodes[1].commit_update()\n",
    "    \n",
    "    if False:\n",
    "        y = torch.rand((2,1))\n",
    "        y_hat = torch.cat((nodes[0].hidden, nodes[1].hidden))\n",
    "        error = torch.nn.MSELoss()(y_hat, y)\n",
    "        error_grad = 2 * (y_hat - y) / 2\n",
    "        error.backward(retain_graph=True)\n",
    "        print(\"===== Actual =====\")\n",
    "        print(nodes[0].W.grad, nodes[1].W.grad)\n",
    "        print(\"===== Calculated =====\")\n",
    "        print(nodes[0].G * error_grad[0].item(), nodes[1].G * error_grad[1].item())\n",
    "        nodes[0].W.grad = None\n",
    "        nodes[1].W.grad = None\n",
    "\n",
    "y = torch.rand((2,1))\n",
    "y_hat = torch.cat((nodes[0].hidden, nodes[1].hidden))\n",
    "error = torch.nn.MSELoss()(y_hat, y)\n",
    "error_grad = 2 * (y_hat - y) / 2\n",
    "error.backward(retain_graph=False)\n",
    "print(nodes[0].W.grad, nodes[1].W.grad)\n",
    "print(nodes[0].G * error_grad[0].item(), nodes[1].G * error_grad[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e00304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
